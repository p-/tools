diff --git a/game_manager/block_controller.py b/game_manager/block_controller.py
index b294234..5c422c3 100644
--- a/game_manager/block_controller.py
+++ b/game_manager/block_controller.py
@@ -38,6 +38,7 @@ class Block_Controller(object):
         nextMove["strategy"]["y_moveblocknum"] = random.randint(1,8)
         # search best nextMove <--
 
+        
         # return nextMove
         print("===", datetime.now() - t1)
         print(nextMove)
diff --git a/game_manager/q_learning/block_controller_train.py b/game_manager/q_learning/block_controller_train.py
index 5a148d7..8cdfb52 100644
--- a/game_manager/q_learning/block_controller_train.py
+++ b/game_manager/q_learning/block_controller_train.py
@@ -123,8 +123,8 @@ class Block_Controller(object):
                     print("Finetuning mode\nLoad {}".format(self.ft_weight), file=f)
                 
             
-        if torch.cuda.is_available():
-            self.model.cuda()
+#        if torch.cuda.is_available():
+#            self.model.cuda()
         
         self.batch_size = config["train"]["batch_size"]
         self.lr = config["train"]["lr"]
@@ -489,8 +489,8 @@ class Block_Controller(object):
             next_actions, next_states = zip(*next_steps.items())
             next_states = torch.stack(next_states)
                        
-            if torch.cuda.is_available():
-                next_states = next_states.cuda()
+#            if torch.cuda.is_available():
+#                next_states = next_states.cuda()
         
             self.model.train()
             with torch.no_grad():
@@ -511,8 +511,8 @@ class Block_Controller(object):
                 next２_steps =self.get_next_func(next_backboard,next_piece_id,next_shape_class)
                 next2_actions, next2_states = zip(*next２_steps.items())
                 next2_states = torch.stack(next2_states)
-                if torch.cuda.is_available():
-                    next2_states = next2_states.cuda()
+#                if torch.cuda.is_available():
+#                    next2_states = next2_states.cuda()
                 self.model.train()
                 with torch.no_grad():
                     next_predictions = self.model(next2_states)[:, 0]
@@ -523,8 +523,8 @@ class Block_Controller(object):
                 next２_steps =self.get_next_func(next_backboard,next_piece_id,next_shape_class)
                 next2_actions, next2_states = zip(*next２_steps.items())
                 next2_states = torch.stack(next2_states)
-                if torch.cuda.is_available():
-                    next2_states = next2_states.cuda()
+#                if torch.cuda.is_available():
+#                    next2_states = next2_states.cuda()
                 self.target_model.train()
                 with torch.no_grad():
                     next_predictions = self.target_model(next2_states)[:, 0]
@@ -535,8 +535,8 @@ class Block_Controller(object):
                 next２_steps =self.get_next_func(next_backboard,next_piece_id,next_shape_class)
                 next2_actions, next2_states = zip(*next２_steps.items())
                 next2_states = torch.stack(next2_states)
-                if torch.cuda.is_available():
-                    next2_states = next2_states.cuda()
+#                if torch.cuda.is_available():
+#                    next2_states = next2_states.cuda()
                 self.model.train()
                 with torch.no_grad():
                     next_predictions = self.model(next2_states)[:, 0]
diff --git a/game_manager/q_learning/block_controller_train_sample.py b/game_manager/q_learning/block_controller_train_sample.py
index be22dbd..53893f7 100644
--- a/game_manager/q_learning/block_controller_train_sample.py
+++ b/game_manager/q_learning/block_controller_train_sample.py
@@ -123,8 +123,8 @@ class Block_Controller(object):
                     print("Finetuning mode\nLoad {}".format(self.ft_weight), file=f)
                 
             
-        if torch.cuda.is_available():
-            self.model.cuda()
+#        if torch.cuda.is_available():
+#            self.model.cuda()
         
         self.batch_size = config["train"]["batch_size"]
         self.lr = config["train"]["lr"]
@@ -492,8 +492,8 @@ class Block_Controller(object):
             next_actions, next_states = zip(*next_steps.items())
             next_states = torch.stack(next_states)
                        
-            if torch.cuda.is_available():
-                next_states = next_states.cuda()
+#            if torch.cuda.is_available():
+#                next_states = next_states.cuda()
         
             self.model.train()
             with torch.no_grad():
@@ -514,8 +514,8 @@ class Block_Controller(object):
                 next２_steps =self.get_next_func(next_backboard, next_piece_id, next_shape_class)
                 next2_actions, next2_states = zip(*next２_steps.items())
                 next2_states = torch.stack(next2_states)
-                if torch.cuda.is_available():
-                    next2_states = next2_states.cuda()
+#                if torch.cuda.is_available():
+#                    next2_states = next2_states.cuda()
                 self.model.train()
                 with torch.no_grad():
                     next_predictions = self.model(next2_states)[:, 0]
@@ -526,8 +526,8 @@ class Block_Controller(object):
                 next２_steps =self.get_next_func(next_backboard,next_piece_id,next_shape_class)
                 next2_actions, next2_states = zip(*next２_steps.items())
                 next2_states = torch.stack(next2_states)
-                if torch.cuda.is_available():
-                    next2_states = next2_states.cuda()
+#                if torch.cuda.is_available():
+#                    next2_states = next2_states.cuda()
                 self.target_model.train()
                 with torch.no_grad():
                     next_predictions = self.target_model(next2_states)[:, 0]
@@ -538,8 +538,8 @@ class Block_Controller(object):
                 next２_steps =self.get_next_func(next_backboard,next_piece_id,next_shape_class)
                 next2_actions, next2_states = zip(*next２_steps.items())
                 next2_states = torch.stack(next2_states)
-                if torch.cuda.is_available():
-                    next2_states = next2_states.cuda()
+#                if torch.cuda.is_available():
+#                    next2_states = next2_states.cuda()
                 self.model.train()
                 with torch.no_grad():
                     next_predictions = self.model(next2_states)[:, 0]
